{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d5c3c6-0ebe-473b-a3e7-a485f2e0f675",
   "metadata": {},
   "source": [
    "# Scent4You"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e0f533",
   "metadata": {},
   "source": [
    "# Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5116f36",
   "metadata": {},
   "source": [
    "* pandas\n",
    "* selenium\n",
    "* webdriver_manager\n",
    "* BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8334dc9-aa93-4ed3-827e-0d1d70f69dd0",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d16d4e6-7c11-43cb-bb44-704be419c7dd",
   "metadata": {},
   "source": [
    "Our dataset was collected from [Perfume 1976](https://www.1976.com.tw/index) and [Wikiparfum](https://www.wikiparfum.com/zh/).\n",
    "\n",
    "[Perfume 1976](https://www.1976.com.tw/index) is a website dedicated to selling perfumes. We collected information on 2,507 perfume products currently being sold on this site, including their descriptions, top/middle/base notes, and fragrance types.\n",
    "\n",
    "[Wikiparfum](https://www.wikiparfum.com/zh/) bills itself as “the world's first perfume encyclopedia,” functioning as a Wikipedia for the fragrance industry. The website compiles detailed data on perfumes and fragrance materials. We obtained their classification data for fragrance materials from this website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a911daf8-62d7-4111-bb31-d243f43bdb61",
   "metadata": {},
   "source": [
    "## Collecting Data on Perfume 1976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError(\n",
    "    \"It is not recommended to run code in this file. \"\n",
    "    \"Please visit https://github.com/wilson-lyc/Scent4You \"\n",
    "    \"to access the standalone source code. \"\n",
    "    \"This section corresponds to the file: 1976_data_collect.ipynb.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e9052-d723-4f86-a495-a36842e8646e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Necessary packages\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.expected_conditions import *\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import StaleElementReferenceException, TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfabab9-e3f9-4d00-b8ff-7c0916ce2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target URL\n",
    "url = 'https://www.1976.com.tw/cat/27?t=all' # female\n",
    "# url = 'https://www.1976.com.tw/cat/40?t=all' # male\n",
    "# url = 'https://www.1976.com.tw/cat/56?t=all' # neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc9190-8656-40a4-9b2e-cf7b13e1fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "SCROLL_PAUSE = 0.5         # Wait time after scrolling the list\n",
    "DETAIL_LOAD_PAUSE = 0.5    # Wait time after opening the detail page\n",
    "BETWEEN_ITEMS_PAUSE = 0.3  # Interval between switching items\n",
    "BATCH_PAUSE = 1            # Extra pause after each batch of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb69135-7c9c-4b95-9ae6-432e7442cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_driver(url):\n",
    "    '''\n",
    "    Open browser\n",
    "    '''\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "    options.add_argument(\"--incognito\")\n",
    "    prefs = {\n",
    "        \"profile.default_content_setting_values.autofill\": 2,\n",
    "        \"profile.password_manager_enabled\": False,\n",
    "        \"credentials_enable_service\": False,\n",
    "        \"autofill.profile_enabled\": False,\n",
    "        \"autofill.address_enabled\": False,\n",
    "        \"autofill.credit_card_enabled\": False,\n",
    "    }\n",
    "    options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "    driver = None\n",
    "    \n",
    "    try:\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "    except Exception as e1:\n",
    "        fallback_path = r\"chromedriver.exe\"\n",
    "        try:\n",
    "            service = Service(fallback_path)\n",
    "            driver = webdriver.Chrome(service=service, options=options)\n",
    "        except Exception as e2:\n",
    "            raise RuntimeError(f\"Failed to initialize ChromeDriver:\\n1) webdriver-manager error: {e1}\\n2) Local driver error: {e2}\")\n",
    "\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(5)\n",
    "    driver.maximize_window()\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3524ae5b-dd34-4bee-96a4-f98bc4308d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_detail_links(driver, wait, max_scroll_rounds=12):\n",
    "    \"\"\"\n",
    "    Collect all detail links from the product list, handling lazy loading.\n",
    "    \"\"\"\n",
    "    collected = []\n",
    "    seen = set()\n",
    "    last_height = 0\n",
    "\n",
    "    for round_idx in range(max_scroll_rounds):\n",
    "        try:\n",
    "            wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.item.prod-item a.inlineblock\")))\n",
    "        except TimeoutException:\n",
    "            print(\"等待商品列表加载超时，提前结束\")\n",
    "            break\n",
    "\n",
    "        anchors = driver.find_elements(By.CSS_SELECTOR, \"div.item.prod-item a.inlineblock\")\n",
    "        if not anchors:\n",
    "            break\n",
    "        for anchor in anchors:\n",
    "            try:\n",
    "                href = anchor.get_attribute(\"href\")\n",
    "                if href and href not in seen:\n",
    "                    seen.add(href)\n",
    "                    collected.append(href)\n",
    "            except StaleElementReferenceException:\n",
    "                continue\n",
    "\n",
    "        driver.execute_script(\"window.scrollBy(0, window.innerHeight * 2);\")\n",
    "        time.sleep(SCROLL_PAUSE)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a523ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fragrance_section(lines):\n",
    "    \"\"\"\n",
    "    Parse scent notes and top/middle/base notes information\n",
    "    \"\"\"\n",
    "    parsed = {\n",
    "        \"fragrance\": \"未提供\",\n",
    "        \"top_notes\": \"未提供\",\n",
    "        \"middle_notes\": \"未提供\",\n",
    "        \"base_notes\": \"未提供\",\n",
    "    }\n",
    "\n",
    "    alias_map = {\n",
    "        \"fragrance\": [\"香調\", \"香调\"],\n",
    "        \"top_notes\": [\"前味\", \"前調\", \"前调\", \"TopNotes\"],\n",
    "        \"middle_notes\": [\"中味\", \"中調\", \"中调\", \"MiddleNotes\", \"HeartNotes\"],\n",
    "        \"base_notes\": [\"後味\", \"后味\", \"後調\", \"后調\", \"BaseNotes\"],\n",
    "    }\n",
    "\n",
    "    for line in lines:\n",
    "        normalized = re.sub(r\"\\s+\", \"\", line)\n",
    "        for key, aliases in alias_map.items():\n",
    "            if any(alias in normalized for alias in aliases):\n",
    "                value = line\n",
    "                if \"：\" in line:\n",
    "                    value = line.split(\"：\", 1)[1].strip()\n",
    "                elif \":\" in line:\n",
    "                    value = line.split(\":\", 1)[1].strip()\n",
    "                parsed[key] = value\n",
    "                break\n",
    "\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a4e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_perfume_details(driver, wait):\n",
    "    \"\"\"\n",
    "    Extract detailed perfume information from the detail page\n",
    "    \"\"\"\n",
    "    info = {\n",
    "        \"name\": \"未知名称\",\n",
    "        \"description\": \"未提供\",\n",
    "        \"fragrance\": \"未提供\",\n",
    "        \"top_notes\": \"未提供\",\n",
    "        \"middle_notes\": \"未提供\",\n",
    "        \"base_notes\": \"未提供\",\n",
    "    }\n",
    "\n",
    "    NAME_XPATH = \"/html/body/div[1]/div[2]/div[2]/div[2]/div[1]\"\n",
    "    DESC_XPATH = \"/html/body/div[1]/div[2]/div[2]/div[2]/div[3]\"\n",
    "    NOTES_XPATH = \"/html/body/div[1]/div[2]/div[2]/div[2]/div[4]\"\n",
    "\n",
    "    try:\n",
    "        name_el = wait.until(EC.presence_of_element_located((By.XPATH, NAME_XPATH)))\n",
    "        info[\"name\"] = name_el.text.strip()\n",
    "    except TimeoutException:\n",
    "        print(\"Name loading timeout\")\n",
    "\n",
    "    try:\n",
    "        desc_el = driver.find_element(By.XPATH, DESC_XPATH)\n",
    "        desc_text = desc_el.text.strip()\n",
    "        if desc_text:\n",
    "            info[\"description\"] = desc_text\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        notes_el = driver.find_element(By.XPATH, NOTES_XPATH)\n",
    "        notes_lines = [line.strip() for line in notes_el.text.splitlines() if line.strip()]\n",
    "        info.update(parse_fragrance_section(notes_lines))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3559e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visit_detail_page(driver, wait, detail_url):\n",
    "    \"\"\"\n",
    "    Open the detail page and extract data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.execute_script(\"window.open(arguments[0], '_blank');\", detail_url)\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        time.sleep(DETAIL_LOAD_PAUSE)\n",
    "        perfume_info = extract_perfume_details(driver, wait)\n",
    "        perfume_info[\"detail_url\"] = detail_url\n",
    "        print(f\"    -> 成功提取: {perfume_info['name']}\")\n",
    "        return perfume_info\n",
    "    except Exception as exc:\n",
    "        print(f\"    -> 抓取 {detail_url} 时出错: {exc}\")\n",
    "        return None\n",
    "    finally:\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(BETWEEN_ITEMS_PAUSE / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a95cc-ded3-4143-828a-c7b027eb9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_perfume_data(driver, csv_filename=\"perfume_data.csv\"):\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    detail_links = collect_detail_links(driver, wait)\n",
    "    perfumes_data = []\n",
    "    fieldnames = [\n",
    "        \"name\",\n",
    "        \"description\",\n",
    "        \"fragrance\",\n",
    "        \"top_notes\",\n",
    "        \"middle_notes\",\n",
    "        \"base_notes\",\n",
    "        \"detail_url\",\n",
    "    ]\n",
    "\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        print(f\"共收集到 {len(detail_links)} 个商品链接需要采集\")\n",
    "\n",
    "        for idx, detail_url in enumerate(detail_links, start=1):\n",
    "            print(f\"正在处理第 {idx} 个商品: {detail_url}\")\n",
    "            perfume_info = visit_detail_page(driver, wait, detail_url)\n",
    "            if perfume_info:\n",
    "                perfumes_data.append(perfume_info)\n",
    "                writer.writerow({key: perfume_info.get(key, \"\") for key in fieldnames})\n",
    "                csvfile.flush()\n",
    "            time.sleep(BETWEEN_ITEMS_PAUSE)\n",
    "            if idx % 10 == 0:\n",
    "                time.sleep(BATCH_PAUSE)\n",
    "\n",
    "    return perfumes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f965f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, filename=\"perfume_data.csv\"):\n",
    "    if not data:\n",
    "        print(\"No data to save\")\n",
    "        return\n",
    "\n",
    "    keys = data[0].keys()\n",
    "\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(f\"Data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3de6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = open_driver(url)\n",
    "try:\n",
    "    print(\"Start scraping perfume data...\")\n",
    "    perfumes_data = scrape_perfume_data(driver)\n",
    "    print(f\"Total {len(perfumes_data)} perfume records scraped\")\n",
    "\n",
    "    # Print part of the results\n",
    "    for i, perfume in enumerate(perfumes_data[:3]):  # Only print the first 3\n",
    "        print(f\"\\nPerfume {i+1}:\")\n",
    "        for key, value in perfume.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred during execution: {str(e)}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4e3e8e",
   "metadata": {},
   "source": [
    "After running the above code, we will obtain three CSV files, each recording data for female, male, and neutral perfumes. The data includes name, description, fragrance, top_notes, middle_notes, base_notes, and detail_url. The three files are located in the data folder as:\n",
    "\n",
    "- `1976_raw_female.csv`\n",
    "- `1976_raw_male.csv`\n",
    "- `1976_raw_unisex.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94656eb5",
   "metadata": {},
   "source": [
    "## Collecting Data on Wikiparfum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743d4b05",
   "metadata": {},
   "source": [
    "Due to anti-scraping measures on Wikiparfum, we were unable to fully automate data collection from the site. Instead, we manually saved the HTML code of the required web pages and used the BeautifulSoup package to parse the local HTML files and extract the data we needed.\n",
    "\n",
    "It is not recommended to run code in this file. Please visit https://github.com/wilson-lyc/Scent4You to access the standalone source code.\n",
    "\n",
    "This section corresponds to the file: `note_class_collect.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347773ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae502a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "HTML_PATH = os.path.join(\"html\", \"wikiparfum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract notes and their classes\n",
    "for filename in os.listdir(HTML_PATH):\n",
    "    if filename.endswith('.html'):\n",
    "        file_path = os.path.join(HTML_PATH, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            html = f.read()\n",
    "            \n",
    "        class_name = filename.replace('.html', '')\n",
    "        print(f\"===== {class_name} =====\")\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        items = soup.find_all(\"div\", class_='items-start')\n",
    "        print(f\"Total notes: {len(items)}\")\n",
    "        \n",
    "        notes_list = []\n",
    "        for item in items:\n",
    "            span = item.find(\"span\", class_='break-all sm:break-normal text-16 mb-1 text-black block overflow-hidden text-ellipsis')\n",
    "            notes_list.append(span.get_text(strip=True))\n",
    "        print(notes_list)\n",
    "        \n",
    "        temp_df = pd.DataFrame({\n",
    "            'note': notes_list,\n",
    "            'class': [class_name] * len(notes_list)\n",
    "        })\n",
    "        \n",
    "        df = pd.concat([df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1503fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "df.to_csv(\"data/note_class.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3c6260",
   "metadata": {},
   "source": [
    "Running this part of the code will generate `note_class.csv` in the `data` folder, recording the fragrance materials and their classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c322c8b7",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac478267",
   "metadata": {},
   "source": [
    "Before conducting data visualization and model training, it is essential to preprocess the data collected from online sources to ensure that it can be used in subsequent analyses. The data requiring cleaning includes **perfume data** (from [Perfume 1976](https://www.1976.com.tw/index)) and **note classification data** (from [Wikiparfum](https://www.wikiparfum.com/zh/))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b902a9",
   "metadata": {},
   "source": [
    "## Cleaning Perfume Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ea702",
   "metadata": {},
   "source": [
    "Perfume Data consists of [1976_raw_female.csv](data/1976_raw_female.csv), [1976_raw_male.csv](data/1976_raw_male.csv), and [1976_raw_neutral.csv](data/1976_raw_neutral.csv). In this section, we:\n",
    "\n",
    "* Add a gender column\n",
    "\n",
    "* Data merging\n",
    "\n",
    "* Translate Traditional Chinese into Simplified Chinese\n",
    "\n",
    "* Remove escape characters from the description column\n",
    "\n",
    "* Delete records with empty top/middle/base notes or fragrance\n",
    "\n",
    "* Remove extra spaces in the notes and fragrance\n",
    "\n",
    "* Choose the first fragrance as classification\n",
    "\n",
    "* Count the number of notes and fragrance\n",
    "\n",
    "* Unified fragrance label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4f8d9",
   "metadata": {},
   "source": [
    "It is not recommended to run code in this file. Please visit https://github.com/wilson-lyc/Scent4You to access the standalone source code.\n",
    "\n",
    "This section corresponds to the file: [1976_data_clean.ipynb](1976_data_clean.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary packages\n",
    "import pandas as pd\n",
    "import opencc\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9846d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load uncleaned data\n",
    "df_male = pd.read_csv(\"data/1976_raw_male.csv\")\n",
    "df_female = pd.read_csv(\"data/1976_raw_female.csv\")\n",
    "df_neutral = pd.read_csv(\"data/1976_raw_neutral.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a gender column\n",
    "df_male['gender'] = 'male'\n",
    "df_female['gender'] = 'female'\n",
    "df_neutral['gender'] = 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a882431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data merging\n",
    "df = pd.concat([df_male, df_female, df_neutral], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1544599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate Traditional Chinese into Simplified Chinese\n",
    "converter = opencc.OpenCC('t2s.json')\n",
    "for col in df.columns:\n",
    "    if col == 'detail_url':\n",
    "        continue\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].apply(lambda x: converter.convert(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove escape characters from the description column\n",
    "if 'description' in df.columns:\n",
    "    df['description'] = df['description'].replace({r'\\r\\n|\\n|\\r': ''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e20a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete records with empty notes or fragrance\n",
    "print(df[['fragrance', 'top_notes', 'middle_notes', 'base_notes']].isna().sum())\n",
    "df = df.dropna(subset=['fragrance', 'top_notes', 'middle_notes', 'base_notes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces in the notes and fragrance\n",
    "for col in ['fragrance', 'top_notes', 'middle_notes', 'base_notes']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: x.replace(' ', '') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the first fragrance as classification\n",
    "df['fragrance'] = df['fragrance'].apply(lambda x: x.split('、')[0] if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f887c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of notes\n",
    "note_columns = ['top_notes', 'middle_notes', 'base_notes']\n",
    "note_counts = {}\n",
    "\n",
    "for col in note_columns:\n",
    "    if col in df.columns:\n",
    "        for s in df[col]:\n",
    "            if isinstance(s, str):\n",
    "                for item in [n.strip() for n in s.split('、') if n.strip()]:\n",
    "                    note_counts[item] = note_counts.get(item, 0) + 1\n",
    "\n",
    "# Save\n",
    "with open('data/note_count.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['note', 'count'])\n",
    "    for item, count in sorted(note_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        writer.writerow([item, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of fragrance\n",
    "fragrance_counts = {}\n",
    "for s in df['fragrance']:\n",
    "    for item in [i.strip() for i in s.split('、') if i.strip()]:\n",
    "        fragrance_counts[item] = fragrance_counts.get(item, 0) + 1\n",
    "\n",
    "# Save\n",
    "with open('data/fragrance_count.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['fragrance', 'count'])\n",
    "    for item, count in sorted(fragrance_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        writer.writerow([item, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unified fragrance label\n",
    "df = df.rename(columns={'fragrance': 'original_fragrance'})\n",
    "map_fragrance = pd.read_csv(\"data/fragrance_map.csv\") # Manually unify the expression of fragrance labels\n",
    "df = df.merge(map_fragrance, how='left', left_on='original_fragrance', right_on='original_fragrance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final cleaned data\n",
    "df.to_csv(\"data/1976_clean.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07145a50",
   "metadata": {},
   "source": [
    "Running this part of the code will generate 3 `csv` files in the `data` folder:  \n",
    "* [ntoe_count.csv](data/ntoe_count.csv): records the frequency of different fragrance notes  \n",
    "* [fragrance_count.csv](data/fragrance_count.csv): records the number of various perfumes  \n",
    "* [1976_clean.csv](data/1976_clean.csv): cleaned perfume dataset  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c0ad42",
   "metadata": {},
   "source": [
    "## Cleaning Note Classification Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0391e",
   "metadata": {},
   "source": [
    "Note classification data consists of [ntoe_count.csv](data/ntoe_count.csv) and [note_class.csv](data/note_class.csv) files. They come from different websites: [ntoe_count.csv](data/ntoe_count.csv) is sourced from [Perfume 1976](https://www.1976.com.tw/index), while [note_class.csv](data/note_class.csv) is sourced from [Wikiparfum](https://www.wikiparfum.com/zh/). We use [Wikiparfum](https://www.wikiparfum.com/zh/) classifications of notes to categorize the perfume notes from [Perfume 1976](https://www.1976.com.tw/index). The challenge lies in the fact that the two websites often describe the same note differently, so we introduce the Qwen3 to help resolve this issue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e727c8f7",
   "metadata": {},
   "source": [
    "It is not recommended to run code in this file. Please visit https://github.com/wilson-lyc/Scent4You to access the standalone source code.\n",
    "\n",
    "This section corresponds to the file: [note_class_map_initial.ipynb](note_class_map_initial.ipynb), [note_class_map_ai.ipynb](note_class_map_ai.ipynb) and [note_class_map_merge.ipynb](note_class_map_merge.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3f75b",
   "metadata": {},
   "source": [
    "### Simple Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd86f97",
   "metadata": {},
   "source": [
    "First, we do not perform any processing on the two files and directly carry out classification matching, starting with assigning classification labels to the notes that are consistently described in both files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac4003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c720d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load note classes\n",
    "note_class = pd.read_csv(\"data/note_class.csv\")\n",
    "note_class = note_class.drop_duplicates(subset=['note'])\n",
    "print(note_class['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load notes\n",
    "df = pd.read_csv(\"data/ntoe_count.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign classes to notes\n",
    "df = df.merge(note_class, how='left', left_on='note', right_on='note')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4178d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "df.to_csv(\"data/note_class_initial.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e9842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record notes without classes\n",
    "not_matched = df[df['class'].isna()]\n",
    "not_matched.to_csv(\"data/note_class_miss.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1968959c",
   "metadata": {},
   "source": [
    "### AI Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c0464a",
   "metadata": {},
   "source": [
    "Classes have been assigned to a subset of notes, and those successfully matched are stored in [note_class_initial.csv](data/note_class_initial.csv). Notes that could not be matched have been recorded in [note_class_miss.csv](data/note_class_miss.csv). Subsequently, the Qwen3 model is employed to classify the unmatched notes.\n",
    "\n",
    "\n",
    "Before running this section of code, please read the API_KEY configuration guide at https://help.aliyun.com/zh/model-studio/first-api-call-to-qwen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a037211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary packages\n",
    "import os\n",
    "import dashscope\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d6f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from environment variable\n",
    "API_KEY=os.getenv('DASHSCOPE_API_KEY')\n",
    "\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"DASHSCOPE_API_KEY environment variable not set. Please set it according to the documentation at https://help.aliyun.com/zh/model-studio/first-api-call-to-qwen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d965e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to request Qwen3 for classification\n",
    "def get_classification(note):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': '你是一个香材分类大师，你需要将香材分类为：东方调、木质香调、果香调、柑橘调、柑苔香调、概念性、海洋调、烟草香调、皮革香调、美食香调、花香调、辛香调、醛香调、青香调、馥奇调、麝香调。不要任何解释，直接输出分类结果，无法分类输出未知。'},\n",
    "        {'role': 'user', 'content': f'{note}'}\n",
    "    ]\n",
    "    response = dashscope.Generation.call(\n",
    "        api_key=API_KEY,\n",
    "        model=\"qwen3-235b-a22b-instruct-2507\",\n",
    "        messages=messages,\n",
    "        result_format='message'\n",
    "    )\n",
    "    return response.output.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dfae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing classes and save\n",
    "df = pd.read_csv('data/note_class_miss.csv')\n",
    "df['class'] = df['note'].apply(get_classification)\n",
    "df['class'] = df['class'].replace('未知', '')\n",
    "df.to_csv('data/note_class_miss_filled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d93233",
   "metadata": {},
   "source": [
    "### Merge Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757d9d7",
   "metadata": {},
   "source": [
    "Thus far, Qwen3 has been employed to assign classes to notes that previously could not be matched. The processed data is stored in [note_class_miss_filled.csv](data/note_class_miss_filled.csv). Next, we merge [note_class_initial.csv](data/note_class_initial.csv) and [note_class_miss_filled.csv](data/note_class_miss_filled.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6aa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_miss = pd.read_csv(\"data/note_class_miss_filled.csv\")\n",
    "df_initial = pd.read_csv(\"note_class_map_initial.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96cae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "note_class_unique = df_miss.drop_duplicates(subset='note', keep='first')\n",
    "mask = df_initial['class'].isna() | (df_initial['class'] == '')\n",
    "df_initial.loc[mask, 'class'] = df_initial.loc[mask, 'note'].map(note_class_unique.set_index('note')['class'])\n",
    "print(df_initial['class'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c02730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "df_initial.to_csv(\"data/note_class_map_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeb3e6c",
   "metadata": {},
   "source": [
    "### Manual Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a6a28",
   "metadata": {},
   "source": [
    "The merged data is stored in [note_class_map_raw.csv](data/note_class_map_raw.csv). At this stage, 111 notes remain without assigned classes, and their categorization must be completed through manual classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a625be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError(\"Please manually classify the unmatched notes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc92b64",
   "metadata": {},
   "source": [
    "The manually classified data is stored in [note_class_map.csv](data/note_class_map.csv)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
