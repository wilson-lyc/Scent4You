{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a6b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92dceda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec36877e",
   "metadata": {},
   "source": [
    "# Note Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a4135d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "note_labels_num = 21\n",
    "note_tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "nem = BertForSequenceClassification.from_pretrained(\"bert-base-chinese\", num_labels=note_labels_num).to(device)\n",
    "state_dict = torch.load(\"models/NEM_v1.pth\", map_location=device)\n",
    "nem.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fef1dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary\n",
    "df_ne = pd.read_csv(\"data/note_embedding_v1.csv\")\n",
    "ne_list = df_ne.iloc[:, 1:].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2607225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def note2vec(note):\n",
    "    # 将香材文本转为向量\n",
    "    nem.eval()\n",
    "    with torch.no_grad():\n",
    "        encoding = note_tokenizer(\n",
    "            note,\n",
    "            truncation=True,\n",
    "            padding='max_length', \n",
    "            max_length=64,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "        outputs = nem.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "    \n",
    "    # 推荐近似香材\n",
    "    embedding = embedding.reshape(1, -1)\n",
    "    similarities = cosine_similarity(embedding, ne_list)[0]\n",
    "    idx = similarities.argmax()\n",
    "    rc_vec = ne_list[idx]\n",
    "    rc_name = df_ne.iloc[idx, 0]\n",
    "    rc_similarity = similarities[idx]\n",
    "    return rc_vec, rc_name, rc_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9df886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_note_list_vec(note_list):\n",
    "    vec_list = []\n",
    "    for note in note_list:\n",
    "        vec, name, similarity = note2vec(note)\n",
    "        vec_list.append(vec)\n",
    "        print(f\"Note: {note} => {name} (similarity: {similarity:.4f})\")\n",
    "    return vec_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38b6113",
   "metadata": {},
   "source": [
    "# Perfume Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67199085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get perfume vector\n",
    "def perfume2vec(top_notes, mid_notes, base_notes):\n",
    "    top_vector = np.array(get_note_list_vec(top_notes))\n",
    "    mid_vector = np.array(get_note_list_vec(mid_notes))\n",
    "    base_vector = np.array(get_note_list_vec(base_notes))\n",
    "    perfume_vec = top_vector * 0.3 + mid_vector * 0.4 + base_vector * 0.3\n",
    "    return perfume_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53c63bc",
   "metadata": {},
   "source": [
    "# Recommend Perfumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a51642de-99f7-4d11-9676-e441ac2531b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load perfume vector list\n",
    "df_pe = pd.read_csv(\"data/perfume_embedding_wa.csv\")\n",
    "pe_list = df_pe.iloc[:, 1:].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6acc8c26-5dba-4cd7-ab0a-edd3fb349cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommended_perfumes(top_notes, mid_notes, base_notes, top_k=5):\n",
    "    perfume_vec = perfume2vec(top_notes, mid_notes, base_notes).reshape(1, -1)\n",
    "    similarities = cosine_similarity(perfume_vec, pe_list)[0]\n",
    "    df_top = df_pe.assign(similarity=similarities).nlargest(top_k, 'similarity')\n",
    "    recommendation = df_top[['name','similarity']].values.tolist()\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98238da9-ef16-4a56-ac12-ab05fb09e130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: 橙子 => 橙子 (similarity: 1.0000)\n",
      "Note: 咖啡 => 咖啡 (similarity: 1.0000)\n",
      "Note: 巧克力 => 巧克力 (similarity: 1.0000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Burberry Goddess 缪斯女神淡香精迷你瓶', 0.8663206008013937],\n",
       " ['Burberry Goddess 缪斯女神淡香精', 0.8611618673029654],\n",
       " ['Ariana Grande MOD Vanilla 摩德香草女性淡香精', 0.8530533604036163],\n",
       " ['Burberry Brit 风格女性淡香精版本', 0.845229121526251],\n",
       " ['Burberry Brit 风格女性淡香精版本TESTER', 0.845229121526251],\n",
       " ['Thierry Mugler Angel 天使女性淡香精', 0.8383740321815104],\n",
       " ['Burberry Brit 风格女性淡香水', 0.8342656784883614],\n",
       " ['Calvin Klein CK Everyone 中性淡香精', 0.8251400590292636],\n",
       " ['Calvin Klein CK 中性淡香精版本迷你瓶', 0.8251400590292636],\n",
       " ['Armaf Odyssey Dubai Chocolat 杜拜巧克力女性淡香精', 0.816680051465698]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "like_top_notes = [\"橙子\"]\n",
    "like_mid_notes = [\"咖啡\"]\n",
    "like_base_notes = [\"巧克力\"]\n",
    "top_k = 10\n",
    "\n",
    "rc_perfumes = get_recommended_perfumes(like_top_notes, like_mid_notes, like_base_notes, top_k)\n",
    "display(rc_perfumes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
