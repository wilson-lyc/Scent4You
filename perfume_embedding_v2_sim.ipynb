{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27508915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e7f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerfumeEmbedding(nn.Module):\n",
    "    def __init__(self, note_dim=768, hidden=256, z_dim=128, num_classes=8, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.phi_top = nn.Sequential(\n",
    "            nn.Linear(note_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.phi_mid = nn.Sequential(\n",
    "            nn.Linear(note_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.phi_base = nn.Sequential(\n",
    "            nn.Linear(note_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.attn_top = nn.Sequential(\n",
    "            nn.Linear(hidden, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        self.attn_mid = nn.Sequential(\n",
    "            nn.Linear(hidden, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        self.attn_base = nn.Sequential(\n",
    "            nn.Linear(hidden, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "        self.rho_top = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.rho_mid = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.rho_base = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim=hidden, num_heads=4, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.rho = nn.Sequential(\n",
    "            nn.Linear(hidden * 6, z_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(z_dim, z_dim), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Linear(z_dim, num_classes)\n",
    "\n",
    "    def aggregate(self, phi, attn_net, rho, notes):\n",
    "        h = phi(notes)\n",
    "        scores = attn_net(h).squeeze(-1)\n",
    "        attn_weights = torch.softmax(scores, dim=1).unsqueeze(-1)\n",
    "        weighted_h = (h * attn_weights).sum(dim=1)\n",
    "        return rho(weighted_h)\n",
    "    \n",
    "    def forward(self, top_notes, mid_notes, base_notes):\n",
    "        h_top = self.aggregate(self.phi_top, self.attn_top, self.rho_top, top_notes)\n",
    "        h_mid = self.aggregate(self.phi_mid, self.attn_mid, self.rho_mid, mid_notes)\n",
    "        h_base = self.aggregate(self.phi_base, self.attn_base, self.rho_base, base_notes)\n",
    "        \n",
    "        h_seq = torch.stack([h_top, h_mid, h_base], dim=1)\n",
    "        h_interact, _ = self.cross_attn(h_seq, h_seq, h_seq)\n",
    "        h_top_i, h_mid_i, h_base_i = h_interact.unbind(dim=1)\n",
    "        \n",
    "        h_all = torch.cat([h_top, h_mid, h_base, h_top_i, h_mid_i, h_base_i], dim=-1)\n",
    "        \n",
    "        z = self.rho(h_all)\n",
    "        logits = self.classifier(z)\n",
    "        return logits, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "672e6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build note2vec dictionary\n",
    "df_note = pd.read_csv(\"data/note_embedding_v1.csv\")\n",
    "note2vec_dict = {row['note']: row.iloc[1:].values.astype(np.float32) for _, row in df_note.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b14722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def note2vec(note_list):\n",
    "    vec = [ note2vec_dict[note] for note in note_list if note in note2vec_dict ]\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f6670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load perfume data\n",
    "df_perfume = pd.read_csv(\"data/1976_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e74489b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = PerfumeEmbedding().to(device)\n",
    "state_dict = torch.load(\"models/PEM_v2.pth\")\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c23b818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip: Miu Miu L'Eau Bleue 春日花园女性淡香精\n",
      "Skip: Marly Castley 卡斯利淡香精中性淡香精行动香氛\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for _,row in df_perfume.iterrows():\n",
    "        top_notes = row['top_notes'].split('、')\n",
    "        mid_notes = row['middle_notes'].split('、')\n",
    "        base_notes = row['base_notes'].split('、')\n",
    "        \n",
    "        top_vecs = note2vec(top_notes)\n",
    "        mid_vecs = note2vec(mid_notes)\n",
    "        base_vecs = note2vec(base_notes)\n",
    "        \n",
    "        # 跳过任何一个为空的样本\n",
    "        if len(top_vecs) == 0 or len(mid_vecs) == 0 or len(base_vecs) == 0:\n",
    "            print(f\"Skip: {row['name']}\")\n",
    "            embeddings.append([np.nan]*128)\n",
    "            continue\n",
    "        \n",
    "        top_vecs = torch.tensor(top_vecs, dtype=torch.float32).to(device).unsqueeze(0)\n",
    "        mid_vecs = torch.tensor(mid_vecs, dtype=torch.float32).to(device).unsqueeze(0)\n",
    "        base_vecs = torch.tensor(base_vecs, dtype=torch.float32).to(device).unsqueeze(0)\n",
    "        \n",
    "        logits, z = model(top_vecs, mid_vecs, base_vecs)\n",
    "        embeddings.append(z.cpu().numpy().squeeze())\n",
    "\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "embeddings_df.insert(0, 'name', df_perfume['name'])\n",
    "embeddings_df = embeddings_df.dropna()\n",
    "embeddings_df.to_csv(\"data/perfume_embedding_v2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
